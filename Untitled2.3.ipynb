{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81f0e51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Êó•‰ªò                                               „ÉÑ„Ç§„Éº„Éà\n",
      "0  81  RT @sousyou13: „ÉØ„ÇØ„ÉÅ„É≥„ÅßÊ≠ª„Çì„Åß„ÅÑ„Çã‰∫∫„ÅåÊ≤¢Â±±„ÅÑ„Çã„ÄÇ\\n„Å®„ÄÅÁü•„ÇäÂêà„ÅÑ„Å´ÂïìÁô∫„Çí„Åó„Åü...\n",
      "1  81                      Êñ∞ÂππÁ∑öÔºÅÊ∫ÄÂì°„Åß„Åó„Åü„Éª„Éª„Éª„Éª\\n„Ç≥„É≠„ÉäÔºü„Éª„Éª„ÉªÂøò„Çå„Å¶„ÅÑ„Çã„ÅÆÔºü\n",
      "2  81  RT @lifeafter_game: #„Çæ„É≥„Éì„Å®ËçíÊµ∑ „É™„É™„Éº„ÇπÈñãÂßãÔºÅüéâ\\n\\nÊµÑÂúü„Å´Âêë„Åë„Å¶...\n",
      "3  81  RT @DAMch_Official: Â§ñÂá∫‰∏≠„Å°„Çá„Å£„Å®‰ºëÊÜ©„Åó„Åü„ÅÑ„ÅÆ„Å´„ÄÅÂñ´Ëå∂Â∫ó„ÇÑ„Ç´„Éï„Çß„ÅØ„Å©„Åì„ÇÇ...\n",
      "4  81  RT @MNHR_Labo: „ÄåÁ¨¨‰∏ÉÊ≥¢„Äç„Åß„ÄÅÊñ∞Âûã„Ç≥„É≠„Éä„ÅåÂéüÂõ†„ÅßÊ≠ª‰∫°„Åó„Åü‰∫∫„ÅØ„ÅÑ„Å™„ÅÑ„ÄÇ\\n\\nÊÑõ...\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "[1119, 1119, 1119, 1119, 1119, 1119, 1119, 1119, 1119, 1119]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import mlask\n",
    "\n",
    "emotion_analyzer = mlask.MLAsk()\n",
    "\n",
    "df = pd.DataFrame(columns = [])\n",
    "for twitter_df in glob.glob(\"C:\\\\Users\\\\kouta\\\\data-twi_1.csv\"):\n",
    "    tmp = pd.read_csv(twitter_df, encoding = \"utf-8\", engine=\"c\", index_col=None)\n",
    "    tmp.columns = ['Êó•‰ªò','„ÉÑ„Ç§„Éº„Éà']\n",
    "    df = pd.concat([df, tmp], ignore_index=True)\n",
    "print(df.head())\n",
    "\n",
    "emotion_lists = []\n",
    "aaa = [0,0,0,0,0,0,0,0,0,0]\n",
    "num=0\n",
    "for text in df['„ÉÑ„Ç§„Éº„Éà']:\n",
    "    num+=1\n",
    "    if num % 1000==0:\n",
    "        print(num)\n",
    "    emotion_list = []\n",
    "    try:\n",
    "        res = emotion_analyzer.analyze(text)\n",
    "    #     print(res)\n",
    "        try:\n",
    "            t = res['emotion']['odoroki']\n",
    "            aaa[0]+=1\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            t = res['emotion']['kowa']\n",
    "            aaa[1]+=1\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            t = res['emotion']['yasu']\n",
    "            aaa[2]+=1\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            t = res['emotion']['yorokobi']\n",
    "            aaa[3]+=1\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            t = res['emotion']['iya']\n",
    "            aaa[4]+=1\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            t = res['emotion']['aware']\n",
    "            aaa[5]+=1\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            t = res['emotion']['haji']\n",
    "            aaa[6]+=1\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            t = res['emotion']['ikari']\n",
    "            aaa[7]+=1\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            t = res['emotion']['suki']\n",
    "            aaa[8]+=1\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            t = res['emotion']['takaburi']\n",
    "            aaa[9]+=1\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    except:\n",
    "        print(text)\n",
    "\n",
    "\n",
    "emotion_df = pd.DataFrame(emotion_lists, columns=['aware', 'haji', 'ikari', 'iya', 'kowa', 'odoroki', 'suki', 'takaburi', 'yasu', 'yorokobi'])\n",
    "print(aaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88ef9e01",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_40044/782402859.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmlask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0memotion_analyzer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMLAsk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-d 'C:\\Program Files\\MeCab\\dic\\ipadic'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0memotion_analyzer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ËøëÂπ¥„Åß„ÅØ„ÄÅË¶™ÊÑõ„ÅÆÊÉÖ„ÇíËæº„ÇÅ„Å¶Âèã‰∫∫„ÄÅÁü•‰∫∫„ÇÑË¶™Êóè„Å´„ÇÇË¥à„Çã„ÅäÊ≠≥ÊöÆ„Å∏„Å®Â∞ë„Åó„Åö„Å§Â§âÂåñ„Åó„Å¶„Åç„Å¶„ÅÑ„Çã„Çà„ÅÜ„Åß„Åô„ÄÇ'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlask\\mlask.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, mecab_arg)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mPY2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[0mmecab_arg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmecab_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmecab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMeCab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmecab_arg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_emodic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mPY2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\MeCab.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m         \u001b[0m_MeCab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTagger_swiginit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_MeCab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_Tagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mparseToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import mlask\n",
    "emotion_analyzer = mlask.MLAsk(\"-d 'C:\\Program Files\\MeCab\\dic\\ipadic'\")\n",
    "emotion_analyzer.analyze('ËøëÂπ¥„Åß„ÅØ„ÄÅË¶™ÊÑõ„ÅÆÊÉÖ„ÇíËæº„ÇÅ„Å¶Âèã‰∫∫„ÄÅÁü•‰∫∫„ÇÑË¶™Êóè„Å´„ÇÇË¥à„Çã„ÅäÊ≠≥ÊöÆ„Å∏„Å®Â∞ë„Åó„Åö„Å§Â§âÂåñ„Åó„Å¶„Åç„Å¶„ÅÑ„Çã„Çà„ÅÜ„Åß„Åô„ÄÇ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c5c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import mlask\n",
    "\n",
    "df = pd.DataFrame(columns = [])\n",
    "for twitter_df in glob.glob(\"csv„Éï„Ç°„Ç§„É´/*.csv\"):\n",
    "    tmp = pd.read_csv(twitter_df, encoding = \"cp932\", engine=\"c\", index_col=None)\n",
    "    tmp.columns = ['Êó•‰ªò','„Ç¢„Ç´„Ç¶„É≥„ÉàÂêç','„ÉÑ„Ç§„Éº„Éà']\n",
    "    df = pd.concat([df, tmp], ignore_index=True)\n",
    "print(df.head())\n",
    "\n",
    "emotion_lists = []\n",
    "num=0\n",
    "for text in df['„ÉÑ„Ç§„Éº„Éà']:\n",
    "    num+=1\n",
    "    if num % 1000==0:\n",
    "        print(num)\n",
    "    emotion_list = []\n",
    "    try:\n",
    "        res = emotion_analyzer.analyze(text)\n",
    "    #     print(res)\n",
    "        try:\n",
    "            t = res['emotion']['odoroki']\n",
    "            emotion_list.append(t)\n",
    "        except:\n",
    "            emotion_list.append([])\n",
    "        try:\n",
    "            t = res['emotion']['kowa']\n",
    "            emotion_list.append(t)\n",
    "        except:\n",
    "            emotion_list.append([])\n",
    "        try:\n",
    "            t = res['emotion']['yasu']\n",
    "            emotion_list.append(t)\n",
    "        except:\n",
    "            emotion_list.append([])\n",
    "        try:\n",
    "            t = res['emotion']['yorokobi']\n",
    "            emotion_list.append(t)\n",
    "        except:\n",
    "            emotion_list.append([])\n",
    "        try:\n",
    "            t = res['emotion']['iya']\n",
    "            emotion_list.append(t)\n",
    "        except:\n",
    "            emotion_list.append([])\n",
    "        try:\n",
    "            t = res['emotion']['aware']\n",
    "            emotion_list.append(t)\n",
    "        except:\n",
    "            emotion_list.append([])\n",
    "        try:\n",
    "            t = res['emotion']['haji']\n",
    "            emotion_list.append(t)\n",
    "        except:\n",
    "            emotion_list.append([])\n",
    "        try:\n",
    "            t = res['emotion']['ikari']\n",
    "            emotion_list.append(t)\n",
    "        except:\n",
    "            emotion_list.append([])\n",
    "        try:\n",
    "            t = res['emotion']['suki']\n",
    "            emotion_list.append(t)\n",
    "        except:\n",
    "            emotion_list.append([])\n",
    "        try:\n",
    "            t = res['emotion']['takaburi']\n",
    "            emotion_list.append(t)\n",
    "        except:\n",
    "            emotion_list.append([])\n",
    "        emotion_lists.append(emotion_list)\n",
    "    except:\n",
    "        emotion_lists.append([[],[],[],[],[],[],[],[],[],[]])\n",
    "        print(text)\n",
    "\n",
    "\n",
    "emotion_df = pd.DataFrame(emotion_lists, columns=['aware', 'haji', 'ikari', 'iya', 'kowa', 'odoroki', 'suki', 'takaburi', 'yasu', 'yorokobi'])\n",
    "print(emotion_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
